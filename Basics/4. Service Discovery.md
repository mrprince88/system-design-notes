Load balancing is often tied with service discovery and global locks. The type of load we want to balance is that of sticky sessions.


Consistent Hashing: https://www.youtube.com/watch?v=UF9Iqmg94tk


Service discovery is a critical component in distributed systems and cloud computing, enabling applications and services to find and communicate with each other. There are several methods for service discovery, each suited to different scenarios and requirements. Here are some of the common approaches:

1. **DNS-Based Service Discovery**:

- This method uses the Domain Name System (DNS) to locate services. Each service is assigned a DNS name, and the DNS server is updated dynamically as services are added, removed, or changed.
- Example: In a Kubernetes cluster, when a new pod is created as part of scaling out a service, its IP address is automatically registered with the cluster's DNS service. Other services can then discover the new instance using its DNS name.

2. **Service Registry/Discovery Agents**:

- Services register themselves with a central registry upon startup, and clients query this registry to find services.
- Example: Using a tool like Consul or Eureka, when a service instance is launched, it registers its address with the central service registry. Clients then query the registry to discover the address of the available service instances.

3. **Client-Side Service Discovery**:

- Clients are responsible for determining the network locations of available service instances and load balancing requests across them.
- Example: In a microservices architecture, when a service is horizontally scaled by adding more instances, these new instances register with a service registry. The client-side service discovery mechanism queries the registry and balances the load among all available instances.

4. **Server-Side Service Discovery**:

- The client makes a request to an intermediate router or load balancer, which is responsible for directing the request to an available service instance.
- Example: When new instances of a service are added, a load balancer like NGINX or HAProxy is updated to include these instances. The load balancer then directs incoming client requests to these new instances based on its load-balancing algorithm.

5. **Self-Announcing Services**:

- Services publish their availability on a common message bus or distributed system like Apache ZooKeeper, where clients can discover them.
- Example: When a service instance is scaled out, it announces its presence on a message bus like Kafka or a distributed system like ZooKeeper. Other services listen on these channels and update their records of available services.

6. **API Gateway**:

- An API Gateway acts as a single entry point for all clients. It can handle service discovery internally and route requests to the appropriate service.
- Example: In a horizontally scaled service scenario, the API Gateway would be aware of all service instances and would route incoming requests to less busy instances.